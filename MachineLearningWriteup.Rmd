---
title: "MachineLeaningWriteup"
author: "Wei-Cheng Yang"
date: "2014年10月24日"
output: html_document
---

Report points:

### data processing: load data
```{r,message=FALSE}
suppressPackageStartupMessages(library(caret))
suppressPackageStartupMessages(library(e1071))
suppressPackageStartupMessages(library(plyr))
suppressPackageStartupMessages(library(dplyr))
train<-tbl_df(read.csv(file = "pml-training.csv"))
test<-tbl_df(read.csv(file = "pml-testing.csv"))
```

### data processing: clean up training set 
from exploratory analysis we know there are many na's and missing data.
we can see these are because the kurtosis,skewness,max and min and summary,..are only available at a regular time interval, our target is to predict the action type and these summary values from a regular time interval are not available so we remove them from the crude database. 
remove all variables with missing value (which are summary figures over a time interval)
remove also timestamp and timewindow for they are not correlated with the activity but only time.

We also remove 10% of the dataset for final estimation for out of sample error.
```{r}
has_na<-numeric(length = 160)
for (val in 1:160)
has_na[val]<-sum(is.na(train[val]))
col_index<-which(has_na==0)
train1<-train[col_index]
train_clean<-train1[-c(12:20,43:48,52:60,74:82)]
train_clean<-train_clean[-c(1:7)]

set.seed(12345)
for_oos<-createDataPartition(train_clean$classe,p = 0.1,list = FALSE)
oos<-train_clean[for_oos,]
train_final<-train_clean[-for_oos,]
```


## Building up the model and cross validation

We will build out model via train function, with gbm method (for I wanted to use boosting with trees, to produce the final classificationing the data to one of the five results). The cross-validation is built inside the function. We will go by default (bootstrapping, with taking 75% of data for training set and 25% for testing set, the default process perform this for 25 times).
```{r,cache=TRUE,message=FALSE}
set.seed(12345)
modfit<-train(classe~.,method="gbm",data=train_final)

```


## Summary about the model we built up
```{r}
modfit
```
We can see from the result that the final model we picked has highes Accuracy ,( measures calculated from repeated cross validating 25 times by bootstrapping). The kappa statistics for measurement of agreement of prediction: kappa is 0.947, which is quite high. (>0.8 considered good fit)
```{r}
summary(modfit)
```
when looking inside the parameters, summary()showed us the relative influence (weighting) of the variables. We can see "roll_belt"" and "pitch_forearm" "yaw_belt" are the ones with most relative influence.  

## Estimate on out of sample error
We estimate by calculating the accuracy of the model we got on the 10% data we intentionally left behind, with the accuracy calculated below.
```{r}
accuracy<-sum(predict(modfit,oos)==oos$classe)/length(oos$classe)
accuracy

```


## test the 20 testing cases
```{r}
predict(modfit,test)

```

The result is generated by predict() command, which produced the results above. The prediction is correct (by submitting the answers I confirmed this.)

